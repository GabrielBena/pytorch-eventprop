{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate (snntorch) vs Eventprop Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import tonic\n",
    "from yingyang.dataset import YinYangDataset\n",
    "\n",
    "import yaml\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"seed\": 42,\n",
    "    \"dataset\": \"ying_yang\",\n",
    "    \"deterministic\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"encoding\": \"latency\",\n",
    "    \"T\": 30,\n",
    "    \"dt\": 1e-3,\n",
    "    \"t_min\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(data_config[\"seed\"])\n",
    "np.random.seed(data_config[\"seed\"])\n",
    "random.seed(data_config[\"seed\"])\n",
    "\n",
    "data_config[\"dataset\"] = data_config[\"dataset\"]\n",
    "if data_config[\"deterministic\"]:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if data_config[\"dataset\"] == \"mnist\":\n",
    "    train_dataset = datasets.MNIST(\n",
    "        data_config[\"data_folder\"],\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        data_config[\"data_folder\"],\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "elif data_config[\"dataset\"] == \"ying_yang\":\n",
    "    train_dataset = YinYangDataset(size=60000, seed=data_config[\"seed\"])\n",
    "    test_dataset = YinYangDataset(size=10000, seed=data_config[\"seed\"] + 2)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset name\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=data_config[\"batch_size\"], shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=data_config[\"batch_size\"], shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventprop.models import SNN, SpikingLinear_ev, SpikingLinear_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of eventprop.models failed: Traceback (most recent call last):\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n",
      "[autoreload of eventprop.training failed: Traceback (most recent call last):\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/gbena/anaconda3/envs/snntorch/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/gbena/SpiNNCloud/Code/SNN/pytorch-eventprop/eventprop/training.py\", line 306\n",
      "    model = \n",
      "            ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_config = {\n",
    "    \"T\": data_config[\"T\"],\n",
    "    \"dt\": data_config[\"dt\"],\n",
    "    \"tau_m\": 20e-3,\n",
    "    \"tau_s\": 5e-3,\n",
    "    \"mu\": 10,\n",
    "    \"resolve_silent\": False,\n",
    "    \"n_hid\": 30,\n",
    "    \"device\": device,\n",
    "    \"get_first_spikes\": False,\n",
    "}\n",
    "\n",
    "n_ins = {\"mnist\": 784, \"ying_yang\": 5 if data_config[\"encoding\"] == \"latency\" else 4}\n",
    "n_outs = {\"mnist\": 10, \"ying_yang\": 3}\n",
    "\n",
    "dims = [n_ins[data_config[\"dataset\"]]]\n",
    "if model_config[\"n_hid\"] is not None and isinstance(model_config[\"n_hid\"], list):\n",
    "    dims.extend(model_config[\"n_hid\"])\n",
    "elif isinstance(model_config[\"n_hid\"], int):\n",
    "    dims.append(model_config[\"n_hid\"])\n",
    "dims.append(n_outs[data_config[\"dataset\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snntorch_model = SNN(dims, dict(model_config, layer_type=str(SpikingLinear_su))).to(device)\n",
    "eventprop_model = SNN(dims, dict(model_config, layer_type=str(SpikingLinear_ev))).to(device)\n",
    "eventprop_model.layers[0].weight.data = snntorch_model.layers[0].weight.data\n",
    "models = {\"snntorch\": snntorch_model, \"eventprop\": eventprop_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 236 (training.py, line 236)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/snntorch/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3526\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\n\u001b[0;31m    from eventprop.training import encode_data\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/SpiNNCloud/Code/SNN/pytorch-eventprop/eventprop/training.py:236\u001b[0;36m\u001b[0m\n\u001b[0;31m    def main(args, use_wandb=False) :\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 236\n"
     ]
    }
   ],
   "source": [
    "from eventprop.training import encode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voltage plot check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "        \n",
    "    data, targets = next(iter(test_loader))\n",
    "    data = data.to(device)\n",
    "    spikes = encode_data(data, data_config)\n",
    "    outs = {n: model(spikes) for n, model in models.items()}\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 5, figsize=(20, 4), sharex=True, sharey=True, constrained_layout=True\n",
    "    )\n",
    "    for t, (ax_model, target) in enumerate(zip(axs.T, targets)):\n",
    "        for ax, (name, out) in zip(ax_model, outs.items()):\n",
    "            voltages = out[1][0][1][:, t].cpu().detach().numpy()\n",
    "            spikes = out[1][0][0][:, t].cpu().detach().numpy()\n",
    "            sns.lineplot(voltages, palette=\"viridis\", ax=ax)\n",
    "            sns.scatterplot(\n",
    "                x=np.where(spikes)[0],\n",
    "                y=np.ones_like(np.where(spikes)[0]),\n",
    "                ax=ax,\n",
    "                color=\"black\",\n",
    "            )\n",
    "            ax.set_title(f\"{name} : {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firing rates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    counts = [0, 0]\n",
    "    frs = [0, 0]\n",
    "    n_batch = len(train_loader)\n",
    "    for (data, target), _ in zip(tqdm(train_loader, total=n_batch), range(n_batch)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        spikes_data = encode_data(data, data_config)\n",
    "        snn_out = models[\"snntorch\"](spikes_data)\n",
    "        event_out = models[\"eventprop\"](spikes_data)\n",
    "        counts = [\n",
    "            c + out[0].unique(return_counts=True)[1]\n",
    "            for c, out in zip(counts, [snn_out, event_out])\n",
    "        ]\n",
    "        for f, s in enumerate([snn_out, event_out]):\n",
    "            frs[f] += s[0].float().sum(0).mean(0)\n",
    "    frs = torch.stack(frs) / n_batch\n",
    "    frs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gbena/SpiNNCloud/Code/SNN/pytorch-eventprop/scripts/model_comparison.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gbena/SpiNNCloud/Code/SNN/pytorch-eventprop/scripts/model_comparison.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventprop.training import train_single_model, test\n",
    "from snntorch.functional.loss import (\n",
    "    ce_temporal_loss,\n",
    "    SpikeTime,\n",
    "    ce_rate_loss,\n",
    "    ce_count_loss,\n",
    ")\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_spike_fn = SpikeTime().first_spike_fn\n",
    "training_config = {\n",
    "    \"n_epochs\": 2,\n",
    "    \"loss\": \"ce_temporal\",\n",
    "    \"first_spike_fn\": first_spike_fn,\n",
    "    'alpha' : 0.\n",
    "}\n",
    "\n",
    "optim_config = {\"lr\": 1e-3, \"weight_decay\": 0, \"optimizer\": \"adam\"}\n",
    "\n",
    "optimizers_type = {\"adam\": torch.optim.Adam, \"sgd\": torch.optim.SGD}\n",
    "optimizers = {\n",
    "    n: optimizers_type[optim_config[\"optimizer\"]](\n",
    "        model.parameters(),\n",
    "        lr=optim_config[\"lr\"],\n",
    "        weight_decay=optim_config[\"weight_decay\"],\n",
    "    )\n",
    "    for n, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_dict_from_nested(config):\n",
    "    flat_dict = {}\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            flat_dict.update(get_flat_dict_from_nested(value))\n",
    "        else:\n",
    "            flat_dict[key] = value\n",
    "    return flat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": data_config,\n",
    "    \"model\": model_config,\n",
    "    \"training\": training_config,\n",
    "    \"optim\": optim_config,\n",
    "}\n",
    "flat_config = get_flat_dict_from_nested(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**flat_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'dataset': 'ying_yang',\n",
       " 'deterministic': True,\n",
       " 'batch_size': 128,\n",
       " 'encoding': 'latency',\n",
       " 'T': 30,\n",
       " 'dt': 0.001,\n",
       " 't_min': 2,\n",
       " 'tau_m': 0.02,\n",
       " 'tau_s': 0.005,\n",
       " 'mu': 10,\n",
       " 'resolve_silent': False,\n",
       " 'n_hid': 30,\n",
       " 'device': device(type='cpu'),\n",
       " 'get_first_spikes': False,\n",
       " 'n_epochs': 2,\n",
       " 'loss': 'ce_temporal',\n",
       " 'first_spike_fn': <bound method Function.apply of <class 'snntorch.functional.loss.SpikeTime.FirstSpike'>>,\n",
       " 'alpha': 0.0,\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 0,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_loader, \"test\": test_loader}\n",
    "\n",
    "if args.loss == \"ce_temporal\":\n",
    "    criterion = ce_temporal_loss()\n",
    "elif args.loss == \"ce_rate\":\n",
    "    criterion = ce_rate_loss()\n",
    "elif args.loss == \"ce_count\":\n",
    "    criterion = ce_count_loss()\n",
    "else:\n",
    "    raise ValueError(\"Invalid loss type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdeb4374251474194d358a87560974e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " | :   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449b60db3c8644d78c90213cd0624e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " | :   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {\n",
    "    n: train_single_model(\n",
    "        model, criterion, optimizers[n], loaders, args, first_spike_fn=first_spike_fn, use_wandb=True\n",
    "    )\n",
    "    for n, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u3rvbc03'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "for name, results in train_results.items():\n",
    "    for trial, metric in product([\"train\", \"test\"], [\"loss\", \"acc\"]):\n",
    "        plot_data.setdefault(f\"{trial}_{metric}\", [])\n",
    "        plot_data[f\"{trial}_{metric}\"].extend(results[f\"{trial}_{metric}\"])\n",
    "    plot_data.setdefault(\"epoch\", [])\n",
    "    plot_data[\"epoch\"].extend(np.arange(len(results[f\"{trial}_{metric}\"])))\n",
    "    plot_data.setdefault(\"model\", [])\n",
    "    plot_data[\"model\"].extend([name] * len(results[f\"{trial}_{metric}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [739.4349976238022,\n",
       "  648.0840718848074,\n",
       "  466.6816376906175,\n",
       "  343.872798691448],\n",
       " 'train_acc': [0.3933961004273504,\n",
       "  0.41855301816239315,\n",
       "  0.47025240384615385,\n",
       "  0.5035389957264957],\n",
       " 'test_loss': [tensor(0.0459),\n",
       "  tensor(0.0412),\n",
       "  tensor(0.0325),\n",
       "  tensor(0.0325),\n",
       "  tensor(0.0236),\n",
       "  tensor(0.0168)],\n",
       " 'test_acc': [0.3968349358974359,\n",
       "  0.4276842948717949,\n",
       "  0.4602363782051282,\n",
       "  0.4602363782051282,\n",
       "  0.5003004807692307,\n",
       "  0.5596955128205128],\n",
       " 'epoch': [0, 1, 2, 0, 1, 2],\n",
       " 'model': ['snntorch',\n",
       "  'snntorch',\n",
       "  'snntorch',\n",
       "  'eventprop',\n",
       "  'eventprop',\n",
       "  'eventprop']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snntorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
