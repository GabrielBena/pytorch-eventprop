{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate (snntorch) vs Eventprop Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from yingyang.dataset import YinYangDataset\n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"seed\": 42,\n",
    "    \"dataset\": \"mnist\",\n",
    "    \"deterministic\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"encoding\": \"latency\",\n",
    "    \"T\": 30,\n",
    "    \"dt\": 1e-3,\n",
    "    \"t_min\": 2,\n",
    "    'data_folder' : '../data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(data_config[\"seed\"])\n",
    "np.random.seed(data_config[\"seed\"])\n",
    "random.seed(data_config[\"seed\"])\n",
    "\n",
    "data_config[\"dataset\"] = data_config[\"dataset\"]\n",
    "if data_config[\"deterministic\"]:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if data_config[\"dataset\"] == \"mnist\":\n",
    "    train_dataset = datasets.MNIST(\n",
    "        data_config[\"data_folder\"],\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        data_config[\"data_folder\"],\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "elif data_config[\"dataset\"] == \"ying_yang\":\n",
    "    train_dataset = YinYangDataset(size=60000, seed=data_config[\"seed\"])\n",
    "    test_dataset = YinYangDataset(size=10000, seed=data_config[\"seed\"] + 2)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset name\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=data_config[\"batch_size\"], shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=data_config[\"batch_size\"], shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventprop.models import SNN, SpikingLinear_ev, SpikingLinear_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_config = {\n",
    "    \"T\": data_config[\"T\"],\n",
    "    \"dt\": data_config[\"dt\"],\n",
    "    \"tau_m\": 20e-3,\n",
    "    \"tau_s\": 5e-3,\n",
    "    \"mu\": 1,\n",
    "    \"resolve_silent\": False,\n",
    "    \"n_hid\": 30,\n",
    "    \"device\": device,\n",
    "    \"get_first_spikes\": False,\n",
    "}\n",
    "\n",
    "n_ins = {\"mnist\": 784, \"ying_yang\": 5 if data_config[\"encoding\"] == \"latency\" else 4}\n",
    "n_outs = {\"mnist\": 10, \"ying_yang\": 3}\n",
    "\n",
    "dims = [n_ins[data_config[\"dataset\"]]]\n",
    "if model_config[\"n_hid\"] is not None and isinstance(model_config[\"n_hid\"], list):\n",
    "    dims.extend(model_config[\"n_hid\"])\n",
    "elif isinstance(model_config[\"n_hid\"], int):\n",
    "    dims.append(model_config[\"n_hid\"])\n",
    "dims.append(n_outs[data_config[\"dataset\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snntorch_model = SNN(dims, **dict(model_config, model_type='snntorch')).to(device)\n",
    "eventprop_model = SNN(dims, **dict(model_config, model_type='eventprop')).to(device)\n",
    "eventprop_model.layers[0].weight.data = snntorch_model.layers[0].weight.data\n",
    "models = {\"snntorch\": snntorch_model, \"eventprop\": eventprop_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventprop.initalization import FluctuationDrivenCenteredNormalInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mu': [0.078, 0.2], 'sigma': [0.045, 0.37]},\n",
       " {'mu': (0.0, 0.0), 'sigma': (0.12448720624794865, 0.6363882091727956)},\n",
       " {'mu': [0, 0], 'sigma': [0.03571428571428571, 0.18257418583505536]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_params = {\n",
    "    \"mnist\": {\n",
    "        \"mu\": [0.078, 0.2],\n",
    "        \"sigma\": [0.045, 0.37],\n",
    "    },\n",
    "    \"ying_yang\": {\"mu\": [1.5, 0.78], \"sigma\": [0.93, 0.1]},\n",
    "}\n",
    "k_aiming_params = {\"mu\": [0, 0], \"sigma\": [1 / np.sqrt(d) for d in dims[:-1]]}\n",
    "\n",
    "dt, T = data_config[\"dt\"], data_config[\"T\"]\n",
    "\n",
    "xi = 3\n",
    "sigma_nu, nu = 1/xi, 15\n",
    "\n",
    "initializer = FluctuationDrivenCenteredNormalInitializer(\n",
    "    sigma_u=sigma_nu, nu=nu, timestep=dt\n",
    ")\n",
    "\n",
    "fluctuation_params = {\n",
    "    name: {\n",
    "        k: v\n",
    "        for k, v in zip(\n",
    "            [\"mu\", \"sigma\"],\n",
    "            list(\n",
    "                zip(\n",
    "                    *[\n",
    "                        initializer._get_weight_parameters_con(layer)\n",
    "                        for layer in model.cpu().layers\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    }\n",
    "    for name, model in models.items()\n",
    "}\n",
    "paper_params[data_config[\"dataset\"]], fluctuation_params['eventprop'], k_aiming_params    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventprop.training import encode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voltage plot check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m spikes \u001b[39m=\u001b[39m encode_data(data, argparse\u001b[39m.\u001b[39mNamespace(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata_config))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m outs \u001b[39m=\u001b[39m {n: model(spikes) \u001b[39mfor\u001b[39;00m n, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m4\u001b[39m), sharex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sharey\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, constrained_layout\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m t, (ax_model, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(axs\u001b[39m.\u001b[39mT, targets)):\n",
      "\u001b[1;32m/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m spikes \u001b[39m=\u001b[39m encode_data(data, argparse\u001b[39m.\u001b[39mNamespace(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata_config))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m outs \u001b[39m=\u001b[39m {n: model(spikes) \u001b[39mfor\u001b[39;00m n, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m4\u001b[39m), sharex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sharey\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, constrained_layout\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22626c6f73736f6d2e65652e69632e61632e756b222c2275736572223a2267623231227d/home/gb21/Code/SNNs/pytorch-eventprop/scripts/model_comparison.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m t, (ax_model, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(axs\u001b[39m.\u001b[39mT, targets)):\n",
      "File \u001b[0;32m~/.conda/envs/eventprop/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/eventprop/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/SNNs/pytorch-eventprop/eventprop/models.py:253\u001b[0m, in \u001b[0;36mSNN.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    252\u001b[0m     reset(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 253\u001b[0m out, all_recs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_first_spikes:\n\u001b[1;32m    255\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutact(out)\n",
      "File \u001b[0;32m~/.conda/envs/eventprop/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/eventprop/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/SNNs/pytorch-eventprop/eventprop/models.py:33\u001b[0m, in \u001b[0;36mRecordingSequential.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m recs \u001b[39m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m---> 33\u001b[0m     x \u001b[39m=\u001b[39m module(x)\n\u001b[1;32m     34\u001b[0m     recs\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/eventprop/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/eventprop/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/SNNs/pytorch-eventprop/eventprop/models.py:187\u001b[0m, in \u001b[0;36mSpikingLinear_su.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    185\u001b[0m voltages \u001b[39m=\u001b[39m []\n\u001b[1;32m    186\u001b[0m \u001b[39mfor\u001b[39;00m t, in_spikes \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39minput\u001b[39m):\n\u001b[0;32m--> 187\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mlinear(in_spikes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[1;32m    188\u001b[0m     spikes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msyn(out)\n\u001b[1;32m    189\u001b[0m     out_spikes\u001b[39m.\u001b[39mappend(spikes)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "if True : \n",
    "        \n",
    "    data, targets = next(iter(test_loader))\n",
    "    data = data.to(device)\n",
    "    spikes = encode_data(data, argparse.Namespace(**data_config))\n",
    "    outs = {n: model(spikes) for n, model in models.items()}\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 5, figsize=(20, 4), sharex=True, sharey=True, constrained_layout=True\n",
    "    )\n",
    "    for t, (ax_model, target) in enumerate(zip(axs.T, targets)):\n",
    "        for ax, (name, out) in zip(ax_model, outs.items()):\n",
    "            voltages = out[1][-1][1][:, t].cpu().detach().numpy()\n",
    "            spikes = out[1][-1][0][:, t].cpu().detach().numpy()\n",
    "            sns.lineplot(voltages, palette=\"viridis\", ax=ax)\n",
    "            sns.scatterplot(\n",
    "                x=np.where(spikes)[0],\n",
    "                y=np.ones_like(np.where(spikes)[0]),\n",
    "                ax=ax,\n",
    "                color=\"black\",\n",
    "            )\n",
    "            ax.set_title(f\"{name} : {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voltages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firing rates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    counts = [0, 0]\n",
    "    frs = [0, 0]\n",
    "    n_batch = len(train_loader)\n",
    "    for (data, target), _ in zip(tqdm(train_loader, total=n_batch), range(n_batch)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        spikes_data = encode_data(data, data_config)\n",
    "        snn_out = models[\"snntorch\"](spikes_data)\n",
    "        event_out = models[\"eventprop\"](spikes_data)\n",
    "        counts = [\n",
    "            c + out[0].unique(return_counts=True)[1]\n",
    "            for c, out in zip(counts, [snn_out, event_out])\n",
    "        ]\n",
    "        for f, s in enumerate([snn_out, event_out]):\n",
    "            frs[f] += s[0].float().sum(0).mean(0)\n",
    "    frs = torch.stack(frs) / n_batch\n",
    "    frs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gbena/SpiNNCloud/Code/SNN/pytorch-eventprop/scripts/model_comparison.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gbena/SpiNNCloud/Code/SNN/pytorch-eventprop/scripts/model_comparison.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventprop.training import train_single_model, test\n",
    "from snntorch.functional.loss import (\n",
    "    ce_temporal_loss,\n",
    "    SpikeTime,\n",
    "    ce_rate_loss,\n",
    "    ce_count_loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_spike_fn = SpikeTime().first_spike_fn\n",
    "training_config = {\n",
    "    \"n_epochs\": 2,\n",
    "    \"loss\": \"ce_temporal\",\n",
    "    \"first_spike_fn\": first_spike_fn,\n",
    "    'alpha' : 0.\n",
    "}\n",
    "\n",
    "optim_config = {\"lr\": 1e-3, \"weight_decay\": 0, \"optimizer\": \"adam\"}\n",
    "\n",
    "optimizers_type = {\"adam\": torch.optim.Adam, \"sgd\": torch.optim.SGD}\n",
    "optimizers = {\n",
    "    n: optimizers_type[optim_config[\"optimizer\"]](\n",
    "        model.parameters(),\n",
    "        lr=optim_config[\"lr\"],\n",
    "        weight_decay=optim_config[\"weight_decay\"],\n",
    "    )\n",
    "    for n, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_dict_from_nested(config):\n",
    "    flat_dict = {}\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            flat_dict.update(get_flat_dict_from_nested(value))\n",
    "        else:\n",
    "            flat_dict[key] = value\n",
    "    return flat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": data_config,\n",
    "    \"model\": model_config,\n",
    "    \"training\": training_config,\n",
    "    \"optim\": optim_config,\n",
    "}\n",
    "flat_config = get_flat_dict_from_nested(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**flat_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'dataset': 'ying_yang',\n",
       " 'deterministic': True,\n",
       " 'batch_size': 128,\n",
       " 'encoding': 'latency',\n",
       " 'T': 30,\n",
       " 'dt': 0.001,\n",
       " 't_min': 2,\n",
       " 'tau_m': 0.02,\n",
       " 'tau_s': 0.005,\n",
       " 'mu': 10,\n",
       " 'resolve_silent': False,\n",
       " 'n_hid': 30,\n",
       " 'device': device(type='cpu'),\n",
       " 'get_first_spikes': False,\n",
       " 'n_epochs': 2,\n",
       " 'loss': 'ce_temporal',\n",
       " 'first_spike_fn': <bound method Function.apply of <class 'snntorch.functional.loss.SpikeTime.FirstSpike'>>,\n",
       " 'alpha': 0.0,\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 0,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_loader, \"test\": test_loader}\n",
    "\n",
    "if args.loss == \"ce_temporal\":\n",
    "    criterion = ce_temporal_loss()\n",
    "elif args.loss == \"ce_rate\":\n",
    "    criterion = ce_rate_loss()\n",
    "elif args.loss == \"ce_count\":\n",
    "    criterion = ce_count_loss()\n",
    "else:\n",
    "    raise ValueError(\"Invalid loss type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdeb4374251474194d358a87560974e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " | :   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449b60db3c8644d78c90213cd0624e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " | :   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = {\n",
    "    n: train_single_model(\n",
    "        model, criterion, optimizers[n], loaders, args, first_spike_fn=first_spike_fn, use_wandb=True\n",
    "    )\n",
    "    for n, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u3rvbc03'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "for name, results in train_results.items():\n",
    "    for trial, metric in product([\"train\", \"test\"], [\"loss\", \"acc\"]):\n",
    "        plot_data.setdefault(f\"{trial}_{metric}\", [])\n",
    "        plot_data[f\"{trial}_{metric}\"].extend(results[f\"{trial}_{metric}\"])\n",
    "    plot_data.setdefault(\"epoch\", [])\n",
    "    plot_data[\"epoch\"].extend(np.arange(len(results[f\"{trial}_{metric}\"])))\n",
    "    plot_data.setdefault(\"model\", [])\n",
    "    plot_data[\"model\"].extend([name] * len(results[f\"{trial}_{metric}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [739.4349976238022,\n",
       "  648.0840718848074,\n",
       "  466.6816376906175,\n",
       "  343.872798691448],\n",
       " 'train_acc': [0.3933961004273504,\n",
       "  0.41855301816239315,\n",
       "  0.47025240384615385,\n",
       "  0.5035389957264957],\n",
       " 'test_loss': [tensor(0.0459),\n",
       "  tensor(0.0412),\n",
       "  tensor(0.0325),\n",
       "  tensor(0.0325),\n",
       "  tensor(0.0236),\n",
       "  tensor(0.0168)],\n",
       " 'test_acc': [0.3968349358974359,\n",
       "  0.4276842948717949,\n",
       "  0.4602363782051282,\n",
       "  0.4602363782051282,\n",
       "  0.5003004807692307,\n",
       "  0.5596955128205128],\n",
       " 'epoch': [0, 1, 2, 0, 1, 2],\n",
       " 'model': ['snntorch',\n",
       "  'snntorch',\n",
       "  'snntorch',\n",
       "  'eventprop',\n",
       "  'eventprop',\n",
       "  'eventprop']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snntorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
